
uwot_transform_detailed

Nice — let’s walk through **each of the six issues** I flagged and what you can do with them.

---

### **1. Distance handling mismatch**

* **Problem**: You’re post-processing HNSW’s return values incorrectly for cosine/inner product.
* **Fix**: Use the same transformation UMAP uses internally:

  * For **Euclidean**: keep `sqrt(distance)` (HNSW returns squared L2).
  * For **Cosine**: if you used `InnerProductSpace`, HNSW gives `1 - cos(x, y)`. So you can just set

    ```cpp
    distance = std::max(0.0f, distance); // already 0..2 range
    ```

    → Drop the `1.0f + distance` shift.
  * For **Manhattan**: leave as is.

---

### **2. Weight computation may collapse**

* **Problem**: The `std::max(weight, 0.01f)` floor makes distant neighbors indistinguishable.
* **Fix**: Lower the floor dramatically or remove it:

  ```cpp
  weight = std::max(weight, 1e-6f);
  ```

  → Keeps numerical stability but preserves distance sensitivity.

---

### **3. Exact match detection too strict**

* **Problem**: Threshold `1e-6 * n_dim^0.3` is too small in high-dim float32 space.
* **Fix**: Relax it — something proportional to `1e-3 / sqrt(n_dim)` works better:

  ```cpp
  float match_threshold = 1e-3f / std::sqrt(static_cast<float>(n_dim));
  ```

  → For `n_dim=350`, that’s \~5e-5, achievable in normalized vectors.

---

### **4. Bandwidth scaling based on `min_dist`**

* **Problem**: `min_dist` is an embedding-space hyperparam, not input-space distance.
* **Fix**: Base bandwidth on neighbor distances only:

  ```cpp
  float base_bandwidth = std::max(1e-3f, model->mean_neighbor_distance * 0.5f);
  ```

  → Removes unintended coupling between input and embedding parameters.

---

### **5. Confidence / percentile / z-score metrics**

* **Problem**: Right now, if `p95_neighbor_distance ≈ min_neighbor_distance`, denominator can blow up.
* **Fix**: Clamp denominators:

  ```cpp
  float denom = std::max(1e-6f, model->p95_neighbor_distance - model->min_neighbor_distance);
  confidence_score[i] = 1.0f - (min_distance - model->min_neighbor_distance) / denom;
  confidence_score[i] = std::clamp(confidence_score[i], 0.0f, 1.0f);
  ```

---

### **6. Embedding memcpy safety**

* **Problem**: No check that caller allocated `embedding` with `n_new_obs * model->embedding_dim`.
* **Fix**: Either enforce via explicit parameter:

  ```cpp
  if (n_embedding_dim != model->embedding_dim) return UWOT_ERROR_INVALID_PARAMS;
  ```

  Or wrap `memcpy` in a loop with index-based writes to avoid silent UB.

---

✅ **Summary of fixes**

* (1) Correct metric post-processing.
* (2) Reduce/remove weight floor.
* (3) Relax exact-match threshold.
* (4) Remove `min_dist` from bandwidth scaling.
* (5) Clamp denominators in metrics.
* (6) Add output buffer safety checks.

---


Nice — thanks for pasting the `uwot_fit_with_progress` implementation. Below I’ll give a compact, actionable plan for handling each of the six issues (1–6) you asked about, plus minimal, copy-pasteable code snippets and exact insertion points in your function so you can patch quickly.

I assume you want *correctness and stability* rather than surgical micro-optimizations. I’ll keep changes small and local, and I’ll point to the most appropriate spots in your code.

---
uwot_fit_with_progress
uwot_fit_with_progress_V2
# Quick summary (one-line per issue)

1. Fix metric/distance interpretation for cosine/inner-product and ensure normalized vectors are unit-length when using cosine.
2. Remove aggressive `weight` floor — clamp at a tiny epsilon (e.g. `1e-6`) instead of `0.01`.
3. Relax exact-match threshold to something robust in float32: `1e-3 / sqrt(n_dim)`.
4. Stop using `min_dist` (embedding hyperparam) to compute input-space bandwidth; base bandwidth on neighbor distances (mean or percentiles).
5. Guard confidence/percentile/z-score denominators with `max(eps, denom)` to avoid division by tiny numbers.
6. Avoid raw `memcpy` blindly: validate expected sizes and copy element-wise into the output buffer (or validate `model->embedding.size()` first).

---

# Where to apply each change (with snippets)

Below I give the snippet and a short explanation where to insert it in your function.

---

## 1) Metric / distance handling — *where:* before building the HNSW space and when normalizing data for cosine

**Why:** if the metric is cosine you must ensure the normalized vectors are unit-length and treat returned HNSW distance as `1 - cosine_similarity` (no `+1` shift). Also, if `determine_normalization_mode(metric)` returns a mode for cosine, ensure it includes per-vector normalization (L2).

**Insert after** you compute `norm_mode` and after `normalized_data` is created (right after normalization), and ensure normalization enforces unit length for cosine:

```cpp
// -- After normalize_data_consistent(...)
if (metric == UWOT_METRIC_COSINE) {
    // Ensure each vector is unit-normalized (HNSW InnerProductSpace expects normalized vectors for cosine)
    for (int i = 0; i < n_obs; ++i) {
        float norm = 0.0f;
        for (int j = 0; j < n_dim; ++j) {
            float v = normalized_data[static_cast<size_t>(i) * n_dim + j];
            norm += v * v;
        }
        norm = std::sqrt(std::max(1e-12f, norm));
        for (int j = 0; j < n_dim; ++j) {
            normalized_data[static_cast<size_t>(i) * n_dim + j] /= norm;
        }
    }
}
```

**Notes:** when converting distances elsewhere (e.g., in transform), handle cosine distances returned by HNSW as already in `[0..2]` or `1 - cos` depending on your `space` implementation — but do **not** add `1.0f + distance`.

If you have a place where you convert HNSW distance to actionable `distance` (e.g., in transform), use:

```cpp
case UWOT_METRIC_COSINE:
    // HNSW returns 1 - cosine_similarity for normalized vectors (range [0,2])
    distance = std::max(0.0f, distance);
    break;
```

---

## 2) Weight floor removal — *where:* immediately after `uwot::smooth_knn` produced `nn_weights`, and also when converting `nn_weights` into `model->nn_weights`

**Why:** `weight = max(weight, 0.01f)` makes all neighbors almost equal for distant points.

**Replace / Insert** right after you compute `nn_weights` (before `convert_to_edges` or when mapping to `model->nn_weights`):

```cpp
// Clamp tiny weights but preserve relative differences
const double MIN_WEIGHT = 1e-6;
for (size_t wi = 0; wi < nn_weights.size(); ++wi) {
    if (nn_weights[wi] < MIN_WEIGHT) nn_weights[wi] = MIN_WEIGHT;
}
```

And when copying to model float vector:

```cpp
for (size_t i = 0; i < nn_distances.size(); i++) {
    model->nn_distances[i] = static_cast<float>(nn_distances[i]);
    // ensure no overly-large floor here either
    model->nn_weights[i] = static_cast<float>(std::max<double>(nn_weights[i], MIN_WEIGHT));
}
```

**Notes:** `1e-6` is small, keeps stability but retains distance sensitivity.

---

## 3) Exact-match threshold — *where:* inside `compute_neighbor_statistics` (or wherever you compute `match_threshold`) and/or where you later detect exact matches in `uwot_transform_detailed`

**Why:** `1e-6 * n_dim^0.3` is too strict — relax to `1e-3 / sqrt(n_dim)`.

**Patch** (example snippet; place in compute/statistics):

```cpp
// Use a more lenient but robust exact-match threshold in float32
float match_threshold = 1e-3f / std::sqrt(static_cast<float>(model->n_dim));
// store in model so transform can reuse exact same threshold
model->exact_match_threshold = match_threshold;
```

Then in transform, use `model->exact_match_threshold` (instead of recomputing something different).

---

## 4) Bandwidth scaling — *where:* in `compute_neighbor_statistics` / `smooth_knn` parameter selection / the place you compute `base_bandwidth` for weight formula

**Why:** `min_dist` is an embedding-space parameter — don't use it to decide Gaussian kernel bandwidth in input space.

**Replace** your `base_bandwidth` calculation with one based on neighbor distances (mean or p50/p95):

```cpp
// Example: use robust neighbor statistics
float eps = 1e-6f;
float mean_neighbor_dist = model->mean_neighbor_distance; // already computed by compute_neighbor_statistics
float median_neighbor_dist = model->median_neighbor_distance > 0.0f ? model->median_neighbor_distance : mean_neighbor_dist;

// Base bandwidth on median or mean (safer than min_dist)
float base_bandwidth = std::max(1e-4f, 0.5f * median_neighbor_dist);

// For far-away points, scale conservatively
float adaptive_bandwidth = base_bandwidth;
if (distance > base_bandwidth * 2.0f) {
    adaptive_bandwidth = std::max(adaptive_bandwidth, distance * 0.3f);
}
```

**Action:** ensure `compute_neighbor_statistics` computes `median_neighbor_distance` or `mean_neighbor_distance`, and store in `model` for transform to reuse.

---

## 5) Confidence / percentile / z-score denominator guards — *where:* after you compute `min_distance`, `p95`, `min_neighbor_distance`, etc.

**Why:** avoid divide-by-zero or huge values when percentiles are degenerate.

**Replace** the denominators with `std::max(epsilon, denom)`:

```cpp
const float EPS = 1e-8f;

// Confidence
if (confidence_score) {
    float denom = std::max(EPS, model->p95_neighbor_distance - model->min_neighbor_distance);
    float normalized_dist = (min_distance - model->min_neighbor_distance) / denom;
    confidence_score[i] = std::clamp(1.0f - normalized_dist, 0.0f, 1.0f);
}

// Percentile rank
if (percentile_rank) {
    if (min_distance <= model->min_neighbor_distance) {
        percentile_rank[i] = 0.0f;
    } else if (min_distance >= model->p99_neighbor_distance) {
        percentile_rank[i] = 99.0f;
    } else {
        float p95_range = std::max(EPS, model->p95_neighbor_distance - model->min_neighbor_distance);
        if (min_distance <= model->p95_neighbor_distance) {
            percentile_rank[i] = 95.0f * (min_distance - model->min_neighbor_distance) / p95_range;
        } else {
            float p99_range = std::max(EPS, model->p99_neighbor_distance - model->p95_neighbor_distance);
            percentile_rank[i] = 95.0f + 4.0f * (min_distance - model->p95_neighbor_distance) / p99_range;
        }
    }
}

// Z-score
if (z_score) {
    float denom_z = std::max(EPS, model->std_neighbor_distance);
    z_score[i] = (min_distance - model->mean_neighbor_distance) / denom_z;
}
```

**Notes:** Use `std::clamp` (C++17) to keep confidence in `[0,1]`.

---

## 6) Embedding memcpy safety — *where:* at the final copy to the `embedding` output at the end of `uwot_fit_with_progress`

**Why:** raw `memcpy` assumes caller allocated `n_obs * embedding_dim` floats. Better to sanity-check the internal model buffer and copy elementwise.

**Replace** the final `memcpy`:

```cpp
// Replace this:
// std::memcpy(embedding, model->embedding.data(),
//     static_cast<size_t>(n_obs) * static_cast<size_t>(embedding_dim) * sizeof(float));

// With a guarded copy:
size_t expected = static_cast<size_t>(n_obs) * static_cast<size_t>(embedding_dim);
if (model->embedding.size() < expected) {
    return UWOT_ERROR_MEMORY; // Or UWOT_ERROR_INVALID_PARAMS depending on your semantics
}
for (size_t i = 0; i < expected; ++i) {
    embedding[i] = model->embedding[i];
}
```

**Optional extra:** Add an API parameter `int out_embedding_dim` that the caller must pass (or verify via `embedding_dim` already present) — return error if `out_embedding_dim != model->embedding_dim`. But the above loop is safer without changing the external API.

---

# Additional small improvements to consider (quick list)

* When building HNSW, set `ef` temporarily higher when building neighbors for statistics and then revert (you already partially do this in transform — consider doing similarly when calling `build_knn_graph` if it uses the index).
* Make sure `compute_neighbor_statistics` and `build_knn_graph` explicitly agree on the same normalization mode and the same HNSW `ef_search` value (store that in `model` and reuse).
* Log the values of `mean_neighbor_distance`, `p95`, `std` during debugging runs so you can tune the `base_bandwidth` multiplier if needed.

---

# Concrete patch plan (apply these 6 small edits)

1. After normalization, unit-normalize vectors if `metric == COSINE`.
2. After `uwot::smooth_knn` compute `nn_weights`, clamp tiny weights with `MIN_WEIGHT = 1e-6`.
3. In `compute_neighbor_statistics`, set `model->exact_match_threshold = 1e-3 / sqrt(n_dim)`.
4. Replace any uses of `model->min_dist` for bandwidth with `0.5 * median_neighbor_distance` or `0.5 * mean_neighbor_distance`.
5. Replace percentile/score computations with guarded denominators as shown.
6. Replace final `memcpy` with the guarded loop.

---

If you want I can:

* produce a fully patched version of `uwot_fit_with_progress` with the six edits applied (I will output the complete function body with the edits in place), **or**
* produce a smaller unified patch/diff that you can drop into your codebase.

Which would you prefer? (If you want the full patched function, I’ll paste it in one go so you can copy-paste.)

uwot_save_model
uwot_load_model

Got it — thanks for pasting your **save/load/info** code.
This part is actually in good shape, but let me highlight a few **critical checks + small improvements** that will make it fully consistent with the six issues we discussed earlier:

---

### 🔑 Observations and Recommendations

1. **Exact-match threshold (issue #3)**

   * You’re not currently saving/loading `exact_match_threshold` in the model file.
   * If you compute it in `compute_neighbor_statistics`, it should also be persisted here — otherwise `uwot_transform_detailed` may use a default/incorrect threshold after reload.
     ✅ **Fix:** Add a field to save/load `model->exact_match_threshold` right after neighbor statistics.

   ```cpp
   // Save
   file.write(reinterpret_cast<const char*>(&model->exact_match_threshold), sizeof(float));

   // Load
   file.read(reinterpret_cast<char*>(&model->exact_match_threshold), sizeof(float));
   ```

---

2. **Bandwidth scaling dependency on `min_dist` (issue #4)**

   * You’re already saving `min_dist` and `spread`.
   * If you replace bandwidth scaling with neighbor-distance–based scaling, you should persist whichever *derived statistic* you rely on (e.g., `median_neighbor_distance`).
     ✅ **Fix:** Add `median_neighbor_distance` to save/load, next to `mean_neighbor_distance`.

---

3. **Confidence / percentile denominator guards (issue #5)**

   * You save `min`, `mean`, `std`, `p95`, `p99`. That’s enough to reconstruct metrics, but remember to use `max(EPS, denom)` when computing after load.
   * No save/load change needed here — just careful usage.

---

4. **Embedding memcpy safety (issue #6)**

   * Good: you serialize embedding size explicitly and resize the vector before reading.
   * When exposing to API callers, just validate `embedding_dim` × `n_vertices == embedding.size()` before `memcpy`.

---

5. **HNSW index consistency**
   ✅ You’ve added:

   * space factory initialization before load
   * constructing HNSW with saved `M`, `ef_construction`, `ef_search`
   * compressed save/load
   * size check vs. `n_vertices`

   That covers the usual pitfalls.

---

6. **Always saving k-NN fallback data (issue #1/#2 tie-in)**
   ✅ Already implemented (`needs_knn = true`).

   * Just ensure that when you copy back `nn_weights`, you’ve applied the smaller floor (e.g. `1e-6` instead of `0.01`).

---

### ⚙️ Suggested Minimal Save/Load Extension

Right after writing neighbor statistics:

```cpp
// Save neighbor statistics
file.write(reinterpret_cast<const char*>(&model->min_neighbor_distance), sizeof(float));
file.write(reinterpret_cast<const char*>(&model->mean_neighbor_distance), sizeof(float));
file.write(reinterpret_cast<const char*>(&model->std_neighbor_distance), sizeof(float));
file.write(reinterpret_cast<const char*>(&model->p95_neighbor_distance), sizeof(float));
file.write(reinterpret_cast<const char*>(&model->p99_neighbor_distance), sizeof(float));
file.write(reinterpret_cast<const char*>(&model->mild_outlier_threshold), sizeof(float));
file.write(reinterpret_cast<const char*>(&model->extreme_outlier_threshold), sizeof(float));

// NEW: Save exact-match threshold + median neighbor distance
file.write(reinterpret_cast<const char*>(&model->exact_match_threshold), sizeof(float));
file.write(reinterpret_cast<const char*>(&model->median_neighbor_distance), sizeof(float));
```

And symmetrically on load:

```cpp
// Read neighbor statistics
file.read(reinterpret_cast<char*>(&model->min_neighbor_distance), sizeof(float));
file.read(reinterpret_cast<char*>(&model->mean_neighbor_distance), sizeof(float));
file.read(reinterpret_cast<char*>(&model->std_neighbor_distance), sizeof(float));
file.read(reinterpret_cast<char*>(&model->p95_neighbor_distance), sizeof(float));
file.read(reinterpret_cast<char*>(&model->p99_neighbor_distance), sizeof(float));
file.read(reinterpret_cast<char*>(&model->mild_outlier_threshold), sizeof(float));
file.read(reinterpret_cast<char*>(&model->extreme_outlier_threshold), sizeof(float));

// NEW: Load exact-match threshold + median neighbor distance
file.read(reinterpret_cast<char*>(&model->exact_match_threshold), sizeof(float));
file.read(reinterpret_cast<char*>(&model->median_neighbor_distance), sizeof(float));
```

---

👉 With these two additions, your model persistence will cover **all six issues** we discussed:

* metric handling (saved through `metric` + normalization mode),
* weights (through `nn_weights`),
* exact-match threshold (new),
* bandwidth scaling (median/mean distance saved),
* confidence/z-score (already saved `mean/std/p95/p99`),
* embedding safety (embedding size saved and checked).

---

Do you want me to go ahead and **give you a unified patched version of `uwot_save_model` and `uwot_load_model`** with these extra fields wired in, so you can drop it in directly?



